name: 'Bunjy AI Code Review'
description: 'Integrate AI into your code repository to analyze file changes within a Pull Request using Gemini Nano'
author: 'mohswell'

inputs:
  BASE_APP_URL:
    description: 'Base URL for the Nestjs web server making API calls to Gemini Nano models'
    required: true
  API_KEY:
    description: 'API key for authentication and authorization grants to Bunjy AI web resources'
    required: true
  TOKEN:
    description: 'Github classic access token for authenticating the repository'
    default: ${{ github.token }}
    required: false
  GENERATE_TESTS:
    description: 'Automatically generate unit tests for changed files'
    required: false
    default: 'false'
  JIRA_BASE_URL:
    description: 'Base URL for Jira instance'
    required: false
  JIRA_USERNAME:
    description: 'Jira username for authentication'
    required: false
  JIRA_API_TOKEN:
    description: 'Jira API token for authentication'
    required: false
  AUTO_LINK_JIRA_ISSUES:
    description: 'Automatically link PR to Jira issues mentioned in title or description'
    required: false
    default: 'true'

permissions:
  contents: write
  pull-requests: write
  issues: write
  checks: read
  metadata: read
  statuses: write

runs:
  using: "composite"
  steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ inputs.TOKEN }}
          ref: ${{ github.event.pull_request.head.ref }}

      - name: Download previous analysis data
        id: download-artifact
        continue-on-error: true
        uses: actions/download-artifact@v3
        with:
          name: analysis-data
          path: .analysis-data

      - name: Initialize analysis data
        shell: bash
        run: |
          mkdir -p .analysis-data
          
          # Initialize last analyzed commit if not exists or if download failed
          if [ ! -f .analysis-data/last_analyzed_commit ] || [ ! -s .analysis-data/last_analyzed_commit ]; then
            # Use the base branch commit as starting point for first analysis
            git rev-parse ${{ github.event.pull_request.base.sha }} > .analysis-data/last_analyzed_commit
          fi
          
          # Initialize analyzed files tracking if not exists
          touch .analysis-data/analyzed_files
          
          echo "LAST_ANALYZED_COMMIT=$(cat .analysis-data/last_analyzed_commit)" >> $GITHUB_ENV
    
      - name: Set up environment
        shell: bash
        run: |
          echo "BASE_APP_URL=${{ inputs.BASE_APP_URL }}" >> $GITHUB_ENV
          echo "API_KEY=${{ inputs.API_KEY }}" >> $GITHUB_ENV
          echo "TOKEN=${{ inputs.TOKEN }}" >> $GITHUB_ENV
          echo "TEST_GENERATION=${{ inputs.GENERATE_TESTS }}" >> $GITHUB_ENV
          echo "JIRA_BASE_URL=${{ inputs.JIRA_BASE_URL }}" >> $GITHUB_ENV
          echo "JIRA_USERNAME=${{ inputs.JIRA_USERNAME }}" >> $GITHUB_ENV
          echo "JIRA_API_TOKEN=${{ inputs.JIRA_API_TOKEN }}" >> $GITHUB_ENV
          echo "AUTO_LINK_JIRA_ISSUES=${{ inputs.AUTO_LINK_JIRA_ISSUES }}" >> $GITHUB_ENV
        
          # Create analysis data directory if it doesn't exist
          mkdir -p .analysis-data

          # Initialize last analyzed commit if not exists
          if [ ! -f .analysis-data/last_analyzed_commit ]; then
            git rev-parse ${{ github.event.pull_request.base.sha }} > .analysis-data/last_analyzed_commit
          fi
          
          echo "LAST_ANALYZED_COMMIT=$(cat .analysis-data/last_analyzed_commit)" >> $GITHUB_ENV

      - name: Fetch branches and Commit Histories
        shell: bash
        run: |
          git fetch origin ${{ github.event.pull_request.base.ref }}:refs/remotes/origin/${{ github.event.pull_request.base.ref }}
          git fetch origin ${{ github.event.pull_request.head.ref }}:refs/remotes/origin/${{ github.event.pull_request.head.ref }}

          # Ensure the branches are checked out
          git checkout ${{ github.event.pull_request.base.ref }}
          git checkout ${{ github.event.pull_request.head.ref }}

          # Fetch detailed commit history between base and head branches 
          commits=$(git log --pretty=format:'%H|%s|%ae|%an|%ce|%cn|%ad' \
                  origin/${{ github.event.pull_request.base.ref }}..origin/${{ github.event.pull_request.head.ref }} | tr '\n' ';')
          echo "COMMIT_HISTORY=$commits" >> $GITHUB_ENV

      # TODO: MODIFY THIS IF THE ABOVE STEP KEEPS FAILING, THIS IS MY ORIGINAL IMPLEMENTATION
      # - name: Fetch branches
      #   shell: bash 
      #   run: |
      #     git fetch origin ${{ github.event.pull_request.base.ref }}:refs/remotes/origin/${{ github.event.pull_request.base.ref }}
      #     git fetch origin ${{ github.event.pull_request.head.ref }}:refs/remotes/origin/${{ github.event.pull_request.head.ref }}

      # - name: Fetch Commit History
      #   shell: bash
      #   run: |
      #     if git rev-parse refs/remotes/origin/${{ github.event.pull_request.base.ref }} >/dev/null 2>&1 && \
      #        git rev-parse refs/remotes/origin/${{ github.event.pull_request.head.ref }} >/dev/null 2>&1; then
      #       # Fetch commit history and escape newlines
      #       commits=$(git log --pretty=format:'%H|%s|%ae|%an|%ce|%cn|%ad' \
      #                refs/remotes/origin/${{ github.event.pull_request.base.ref }}..refs/remotes/origin/${{ github.event.pull_request.head.ref }} | tr '\n' ';')
      #     else
      #       echo "Unable to fetch commit history." >&2
      #       exit 1
      #     fi
      #     echo "COMMIT_HISTORY=$commits" >> $GITHUB_ENV

      - name: Set PR Environment Variables
        shell: bash
        run: |
          # Ensure PR number is always set
          PR_NUMBER="${{ github.event.pull_request.number }}"
          if [ -z "$PR_NUMBER" ]; then
            echo "PR_NUMBER from github.event: $PR_NUMBER"
            echo "github.event contents:"
            cat $GITHUB_EVENT_PATH
            exit 1
          fi
          
          echo "PR_NUMBER=$PR_NUMBER" >> $GITHUB_ENV
          echo "PR_TITLE=${{ github.event.pull_request.title }}" >> $GITHUB_ENV
          echo "PR_AUTHOR=${{ github.event.pull_request.user.login }}" >> $GITHUB_ENV
          echo "PR_URL=${{ github.event.pull_request.html_url }}" >> $GITHUB_ENV
          echo "BASE_BRANCH=${{ github.event.pull_request.base.ref }}" >> $GITHUB_ENV
          echo "HEAD_BRANCH=${{ github.event.pull_request.head.ref }}" >> $GITHUB_ENV
                    
      - name: Fetch PR Details
        env:
          GH_TOKEN: ${{ env.TOKEN }}
        shell: bash
        run: |
          # Debug: Print out available environment variables
          echo "Debugging PR Number Retrieval"
          echo "GITHUB_EVENT_PATH: $GITHUB_EVENT_PATH"
          echo "GITHUB_REPOSITORY: $GITHUB_REPOSITORY"
          
          # Extract PR number directly from the GitHub event file
          PR_NUMBER=$(jq -r '.pull_request.number // empty' "$GITHUB_EVENT_PATH")
          
          # Fallback method if PR number is not found
          if [ -z "$PR_NUMBER" ]; then
            PR_NUMBER="${{ github.event.pull_request.number }}"
          fi
          
          # Validate PR Number
          if [ -z "$PR_NUMBER" ]; then
            echo "Error: Unable to determine PR Number"
            exit 1
          fi
          
          echo "Detected PR Number: $PR_NUMBER"
          
          # Fetch PR details, ensuring mandatory fields
          pr_details=$(gh api repos/${GITHUB_REPOSITORY}/pulls/${PR_NUMBER})
          
          # Ensure PR details are retrieved
          if [ -z "$pr_details" ]; then
            echo "Error: Unable to fetch PR details"
            exit 1
          fi
          
          # Safely extract and encode description to handle multiline and special characters
          PR_DESCRIPTION=$(echo $pr_details | jq -r '.body // empty' | base64 -w 0)
          
          # Set environment variables with careful encoding
          echo "PR_NUMBER=$PR_NUMBER" >> $GITHUB_ENV
          echo "PR_TITLE=$(echo $pr_details | jq -r '.title // empty' | base64 -w 0)" >> $GITHUB_ENV
          echo "PR_DRAFT=$(echo $pr_details | jq -r '.draft // false')" >> $GITHUB_ENV
          echo "PR_LABELS=$(echo $pr_details | jq -r '.labels | map(.name) | join(",") // empty')" >> $GITHUB_ENV
          echo "PR_REVIEWERS=$(echo $pr_details | jq -r '.requested_reviewers | map(.login) | join(",") // empty')" >> $GITHUB_ENV
          echo "PR_ADDITIONS=$(echo $pr_details | jq -r '.additions // 0')" >> $GITHUB_ENV
          echo "PR_DELETIONS=$(echo $pr_details | jq -r '.deletions // 0')" >> $GITHUB_ENV
          echo "PR_CHANGED_FILES=$(echo $pr_details | jq -r '.changed_files // 0')" >> $GITHUB_ENV
          echo "PR_MERGEABLE=$(echo $pr_details | jq -r '.mergeable // false')" >> $GITHUB_ENV
          echo "PR_DESCRIPTION=$PR_DESCRIPTION" >> $GITHUB_ENV
          echo "PR_AUTHOR_USERNAME=$(echo $pr_details | jq -r '.user.login // empty')" >> $GITHUB_ENV
          echo "PR_AUTHOR_AVATAR=$(echo $pr_details | jq -r .user.avatar_url)" >> $GITHUB_ENV
          echo "PR_BASE_REPO=$(echo $pr_details | jq -r .base.repo.full_name)" >> $GITHUB_ENV
          echo "PR_HEAD_REPO=$(echo $pr_details | jq -r .head.repo.full_name)" >> $GITHUB_ENV
          echo "PR_COMMENTS=$(echo $pr_details | jq -r .comments)" >> $GITHUB_ENV
          echo "PR_CREATED_AT=$(echo $pr_details | jq -r .created_at)" >> $GITHUB_ENV
          echo "PR_UPDATED_AT=$(echo $pr_details | jq -r .updated_at)" >> $GITHUB_ENV
          echo "PR_CLOSED_AT=$(echo $pr_details | jq -r .closed_at)" >> $GITHUB_ENV
          echo "PR_MERGED_AT=$(echo $pr_details | jq -r .merged_at)" >> $GITHUB_ENV

      - name: Save Pull Request Metadata and user information to server
        shell: bash
        run: |
          # Ensure all required environment variables are set and not empty
          [[ -z "$PR_NUMBER" ]] && { echo "PR_NUMBER is empty"; exit 1; }

          # Convert PR_NUMBER to integer
          PR_NUMBER=$(echo "$PR_NUMBER" | sed 's/[^0-9]*//g')

          # Sanitize and set defaults more strictly
          export PR_DRAFT=$(echo "${PR_DRAFT:-false}" | tr '[:upper:]' '[:lower:]')
          export PR_LABELS=$(echo "${PR_LABELS:-}" | tr -d ' ')
          export PR_REVIEWERS=$(echo "${PR_REVIEWERS:-}" | tr -d ' ')
          export PR_COMMENTS=${PR_COMMENTS:-0}
          export PR_ADDITIONS=${PR_ADDITIONS:-0}
          export PR_DELETIONS=${PR_DELETIONS:-0}
          export PR_CHANGED_FILES=${PR_CHANGED_FILES:-0}
          export PR_MERGEABLE=$(echo "${PR_MERGEABLE:-false}" | tr '[:upper:]' '[:lower:]')
          
          # Metadata for commits          
          # Validate commit history
          if [[ "$COMMIT_HISTORY" == "Unable to fetch commit history." || -z "$COMMIT_HISTORY" ]]; then
            echo "Error: Commit history is invalid or empty. Aborting."
            exit 1
          fi

          # Validate PR number explicitly
          if [[ -z "$PR_NUMBER" || "$PR_NUMBER" == "null" ]]; then
            echo "Error: PR_NUMBER is missing or invalid"
            exit 1
          fi

          echo "Sending metadata to server..."

          IFS=$'\n'
          commit_list=()
          for commit in ${COMMIT_HISTORY}; do
            IFS='|' read -r sha message author_email author_name committer_email committer_name date <<<"$commit"

            # Escape commit message
            message=$(echo "$message" | jq -Rs .)

            # Fetch commit stats (fallback to 0 if stats cannot be retrieved)
            stats=$(git show --stat --format='' "$sha" | tail -n1 || echo "")
            files_changed=$(echo "$stats" | grep -oE '[0-9]+ file' | cut -d' ' -f1 || echo "0")
            insertions=$(echo "$stats" | grep -oE '[0-9]+ insertion' | cut -d' ' -f1 || echo "0")
            deletions=$(echo "$stats" | grep -oE '[0-9]+ deletion' | cut -d' ' -f1 || echo "0")

            commit_list+=("{
              \"sha\":\"$sha\",
              \"message\":$message,
              \"author_email\":\"$author_email\",
              \"author_name\":\"$author_name\",
              \"committer_email\":\"$committer_email\",
              \"committer_name\":\"$committer_name\",
              \"date\":\"$date\",
              \"stats\": {
                \"additions\": ${insertions:-0},
                \"deletions\": ${deletions:-0},
                \"changed_files\": ${files_changed:-0}
              }
            }")
          done

          # Build JSON array for commits
          commit_json=$(printf "%s," "${commit_list[@]}")
          commit_json="[${commit_json%,}]"

          # Generate metadata
          metadata=$(jq -n \
            --arg pr_number "$PR_NUMBER" \
            --arg pr_title "$PR_TITLE" \
            --arg pr_author "$PR_AUTHOR" \
            --arg pr_url "$PR_URL" \
            --arg base_branch "$BASE_BRANCH" \
            --arg head_branch "$HEAD_BRANCH" \
            --arg description "${PR_DESCRIPTION:-null}" \
            --arg author_username "$PR_AUTHOR_USERNAME" \
            --arg author_avatar "$PR_AUTHOR_AVATAR" \
            --arg base_repository "$PR_BASE_REPO" \
            --arg head_repository "$PR_HEAD_REPO" \
            --arg draft "$PR_DRAFT" \
            --arg labels "${PR_LABELS:-}" \
            --arg reviewers "${PR_REVIEWERS:-}" \
            --arg created_at "$PR_CREATED_AT" \
            --arg updated_at "$PR_UPDATED_AT" \
            --arg closed_at "${PR_CLOSED_AT:-null}" \
            --arg merged_at "${PR_MERGED_AT:-null}" \
            --argjson mergeable "${PR_MERGEABLE:-null}" \
            --argjson stats "{
              \"comments\": ${PR_COMMENTS:-0},
              \"additions\": ${PR_ADDITIONS:-0},
              \"deletions\": ${PR_DELETIONS:-0},
              \"changedFiles\": ${PR_CHANGED_FILES:-0}
            }" \
            --argjson commits "$commit_json" \
            '{
              prNumber: $pr_number,
              prTitle: $pr_title,
              prAuthor: $pr_author,
              description: ($description | select(. != null)),
              authorUsername: $author_username,
              authorAvatar: $author_avatar,
              prUrl: $pr_url,
              baseBranch: $base_branch,
              headBranch: $head_branch,
              baseRepository: $base_repository,
              headRepository: $head_repository,
              isDraft: ($draft == "true"),
              labels: ($labels | select(. != null and . != "") | split(",") | map(. | gsub("^[ \t]+|[ \t]+$"; "")) | map(select(. != ""))),  # White spaces Trimming
              reviewers: ($reviewers | split(",") | map(select(. != ""))),
              stats: $stats,
              mergeable: $mergeable,
              createdAt: $created_at,
              updatedAt: $updated_at,
              closedAt: ($closed_at | select(. != null)),
              mergedAt: ($merged_at | select(. != null)),
              commits: $commits
            }')

          echo "Metadata: $metadata"
          echo "PR_NUMBER: $PR_NUMBER"

          # Send metadata to the server
          curl -v -X POST "$BASE_APP_URL/github/store-data" \
            -H "Authorization: Bearer $API_KEY" \
            -H "Content-Type: application/json" \
            -d "$metadata" \
            --connect-timeout 10 \
            --max-time 30 -v

        env:
          BASE_APP_URL: ${{ inputs.BASE_APP_URL }}
          API_KEY: ${{ inputs.API_KEY }}
          PR_NUMBER: ${{ env.PR_NUMBER }}
          PR_TITLE: ${{ env.PR_TITLE }}
          TOKEN: ${{ inputs.TOKEN }}
          PR_AUTHOR: ${{ env.PR_AUTHOR }}
          PR_URL: ${{ env.PR_URL }}
          BASE_BRANCH: ${{ env.BASE_BRANCH }}
          HEAD_BRANCH: ${{ env.HEAD_BRANCH }}
          COMMIT_HISTORY: ${{ env.COMMIT_HISTORY }}

      - name: Analyze Changed Files
        shell: bash
        run: |       
          echo "Analyzing changed files..."

          # Get last analyzed commit
          last_analyzed_commit=$(cat .analysis-data/last_analyzed_commit)
          current_commit=$(git rev-parse HEAD)

          echo "Last analyzed commit: ${last_analyzed_commit}"
          echo "Current commit: ${current_commit}"

          # Get only new changes since last analysis
          changed_files=$(git diff --name-only "${last_analyzed_commit}" "${current_commit}")

          # If no files have changed
          if [ -z "$changed_files" ]; then
            echo "No new changes to analyze"
            exit 0
          fi

          echo "Files changed:"
          echo "$changed_files"

          # Tracked and analyzed files
          # analyzed_files=()
          # previous_analyzed_files=()
          
          # Load previously analyzed files
          declare -A analyzed_files_map
          if [ -f .analysis-data/analyzed_files ]; then
            while IFS= read -r file; do
              analyzed_files_map["$file"]=1
            done < .analysis-data/analyzed_files
          fi

          analysis_results=""
          new_analyzed_files=()

          for file in $changed_files; do
            # Skip if file was already analyzed
            if [[ -n "${analyzed_files_map[$file]}" ]]; then
              echo "Skipping already analyzed file: $file"
              continue
            fi

            # Check file extensions to analyze
            allowed_extensions=("js" "ts" "yml" "yaml" "md" "py" "dart" "tsx" "jsx" "vue" "java" "css" "sh" "env" "html" "json" "xml" "php" "rb" "go" "swift" "c" "cpp" "h" "hpp" "cs" "vb" "fs" "scala" "kt" "tf" "groovy" "rs" "sql")
            file_extension="${file##*.}"


            # Check if file is supported and not previously analyzed --TODO: Uncomment this later if the second if statement fails
            # if [[ " ${allowed_extensions[@]} " =~ " ${file_extension} " ]] && 
            #    [[ ! " ${previous_analyzed_files[@]} " =~ " ${file} " ]]; then
            if [[ " ${allowed_extensions[@]} " =~ " ${file_extension} " ]]; then
              echo "Analyzing file: $file"
              
              # Get diff for this specific file
              diff_output=$(git diff "${last_analyzed_commit}" "${current_commit}" -- "$file")
              
              # Calculate additions and deletions
              additions=$(echo "$diff_output" | grep "^+" | grep -v "^+++" | wc -l)
              deletions=$(echo "$diff_output" | grep "^-" | grep -v "^---" | wc -l)
              
              if [ -n "$diff_output" ]; then
                # Escape diff for JSON
                markdown_diff="### File: \`$file\`\n\n\`\`\`diff\n${diff_output}\n\`\`\`"
                escaped_diff=$(echo "$markdown_diff" | jq -sR .)
                
                # Send file analysis to storage endpoint
                curl -s -X POST "${BASE_APP_URL}/github/store-file-analysis" \
                  -H "Authorization: Bearer ${API_KEY}" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"prNumber\": \"${PR_NUMBER}\",
                    \"filePath\": \"${file}\",
                    \"additions\": ${additions},
                    \"deletions\": ${deletions},
                    \"rawDiff\": ${escaped_diff}
                  }"
                
                # Send diff to AI analysis endpoint
                result=$(curl -s -X POST "${BASE_APP_URL}/gemini/analyze-code" \
                  -H "Authorization: Bearer ${API_KEY}" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"code\": ${escaped_diff},
                    \"pr_number\": \"${PR_NUMBER}\",
                    \"file_path\": \"${file}\"
                  }")
                
                if [ -n "$result" ]; then
                  analysis_results="${analysis_results}\n## Analysis for \`$file\`\n${result}"
                  analyzed_files+=("$file")
                fi
              fi
            else
              echo "Skipping already analyzed or unsupported file: $file"
            fi
          done

          # Update last analyzed commit
          echo "${current_commit}" > .analysis-data/last_analyzed_commit
          
          # Combine and deduplicate analyzed files --TODO: Uncomment this out when the workflow fails, my original implementation
          # unique_analyzed_files=($(printf "%s\n" "${previous_analyzed_files[@]}" "${analyzed_files[@]}" | sort -u))
          # printf "%s\n" "${unique_analyzed_files[@]}" > .analysis-data/analyzed_files

          # Append new analyzed files to existing list
          for new_file in "${new_analyzed_files[@]}"; do
            echo "$new_file" >> .analysis-data/analyzed_files
          done
          
          # Save results for comment
          echo "ANALYSIS_RESULTS<<EOF" >> $GITHUB_ENV
          echo -e "$analysis_results" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

          # If auto-generate tests is enabled, set environment variable
          if [[ "$GENERATE_TESTS" == "true" ]]; then
            echo "GENERATE_TESTS=true" >> $GITHUB_ENV
          fi
        env:
          BASE_APP_URL: ${{ env.BASE_APP_URL }}
          TOKEN: ${{ env.TOKEN }}
          API_KEY: ${{ env.API_KEY }}
          GITHUB_BASE_REF: ${{ github.event.pull_request.base.ref }}
          GITHUB_HEAD_SHA: ${{ github.event.pull_request.head.sha }}
          LAST_ANALYZED_COMMIT: ${{ env.LAST_ANALYZED_COMMIT }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          GENERATE_TESTS: ${{ inputs.GENERATE_TESTS }}

      - name: Save analysis data
        uses: actions/upload-artifact@v3
        with:
          name: analysis-data
          path: .analysis-data
          retention-days: 1
 
     - name: Jira Integration and Issue Linking
        shell: bash
        run: |
          # Debug input values
          echo "PR Title: ${PR_TITLE}"
          echo "PR Description: ${PR_DESCRIPTION}"
          echo "Branch Name: ${GITHUB_HEAD_REF}"

          # Function to extract Jira issues from text
          extract_jira_issues() {
            echo "$1" | grep -oE '[A-Z]+-[0-9]+' || true
          }

          # Try to find Jira issues in all possible locations
          title_issues=$(extract_jira_issues "$PR_TITLE")
          desc_issues=$(extract_jira_issues "$PR_DESCRIPTION")
          branch_issues=$(extract_jira_issues "$GITHUB_HEAD_REF")

          # Combine all found issues and remove duplicates
          all_issues=$(echo -e "${title_issues}\n${desc_issues}\n${branch_issues}" | sort -u | grep . || true)

          # Debug output
          echo "Issues found in title: $title_issues"
          echo "Issues found in description: $desc_issues"
          echo "Issues found in branch: $branch_issues"
          echo "All unique issues: $all_issues"

          # If no issues found, exit successfully
          if [[ -z "$all_issues" ]]; then
            echo "No Jira issues found in PR title, description, or branch name"
            exit 0
          fi

          # Process each unique Jira issue
          echo "$all_issues" | while read issue_key; do
            if [[ -z "$issue_key" ]]; then
              continue
            fi
            
            echo "Processing Jira issue: $issue_key"

            # Prepare AI analysis results for Jira comment
            jira_comment="# Pull Request Analysis for $issue_key

## PR Details
- **PR Number:** #${PR_NUMBER}
- **Author:** ${PR_AUTHOR}
- **Branch:** ${GITHUB_HEAD_REF}
- **Location Found:** $(
  locations=""
  [[ "$title_issues" == *"$issue_key"* ]] && locations+="PR Title "
  [[ "$desc_issues" == *"$issue_key"* ]] && locations+="PR Description "
  [[ "$branch_issues" == *"$issue_key"* ]] && locations+="Branch Name "
  echo "$locations"
)

## Code Analysis
${ANALYSIS_RESULTS}

## Suggested Actions
- Review the code changes
- Check alignment with issue requirements
- Validate test coverage

*Automated analysis by Mintify AI*"

            # Escape the comment for JSON
            escaped_comment=$(echo "$jira_comment" | jq -sR .)

            # Post comment to Jira
            echo "Posting comment to Jira issue ${issue_key}"
            curl_response=$(curl -s -w "\n%{http_code}" -X POST \
              "${JIRA_BASE_URL}/rest/api/3/issue/${issue_key}/comment" \
              -H "Authorization: Basic $(echo -n "${JIRA_USERNAME}:${JIRA_API_TOKEN}" | base64)" \
              -H "Content-Type: application/json" \
              -d "{\"body\": ${escaped_comment}}")
            
            http_code=$(echo "$curl_response" | tail -n1)
            if [[ "$http_code" -ge 200 && "$http_code" -lt 300 ]]; then
              echo "Successfully posted comment to ${issue_key}"
            else
              echo "Failed to post comment to ${issue_key}, but continuing..."
            fi

            # Link PR to Jira
            echo "Linking PR to Jira issue ${issue_key}"
            curl_response=$(curl -s -w "\n%{http_code}" -X POST \
              "${JIRA_BASE_URL}/rest/api/3/issue/${issue_key}/remotelink" \
              -H "Authorization: Basic $(echo -n "${JIRA_USERNAME}:${JIRA_API_TOKEN}" | base64)" \
              -H "Content-Type: application/json" \
              -d "{
                \"globalId\": \"github-pr-${PR_NUMBER}\",
                \"application\": {
                  \"name\": \"GitHub\",
                  \"type\": \"com.github.integration\"
                },
                \"relationship\": \"mentioned in\",
                \"object\": {
                  \"url\": \"${PR_URL}\",
                  \"title\": \"${PR_TITLE}\",
                  \"icon\": {
                    \"url16x16\": \"https://github.com/favicon.ico\"
                  }
                }
              }")
            
            http_code=$(echo "$curl_response" | tail -n1)
            if [[ "$http_code" -ge 200 && "$http_code" -lt 300 ]]; then
              echo "Successfully linked PR to ${issue_key}"
            else
              echo "Failed to link PR to ${issue_key}, but continuing..."
            fi
          done
        env:
          JIRA_BASE_URL: ${{ env.JIRA_BASE_URL }}
          JIRA_USERNAME: ${{ env.JIRA_USERNAME }}
          JIRA_API_TOKEN: ${{ env.JIRA_API_TOKEN }}
          AUTO_LINK_JIRA_ISSUES: ${{ env.AUTO_LINK_JIRA_ISSUES }}
          PR_TITLE: ${{ github.event.pull_request.title }}
          PR_DESCRIPTION: ${{ github.event.pull_request.body }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          PR_AUTHOR: ${{ github.event.pull_request.user.login }}
          PR_URL: ${{ github.event.pull_request.html_url }}
          ANALYSIS_RESULTS: "Analysis results placeholder"

      - name: Post Initial Analysis Comment
        if: env.ANALYSIS_RESULTS != ''
        shell: bash
        run: |          
          echo "Posting comment on PR..."
          
          # Function to clean up AI analysis results
          clean_analysis_results() {
            local results="$1"
            # Remove JSON formatting, quotes, and parse out actual content
            echo "$results" | sed -E 's/.*"formattedResponse":"?//; s/"[[:space:]]*}$//; s/\\n/\n/g; s/\\\"/"/g'
          }

          # Clean and process analysis results
          CLEANED_ANALYSIS_RESULTS=$(clean_analysis_results "${ANALYSIS_RESULTS}")

          COMMENT_BODY=$(cat << EOF
          # Code Analysis Report

          ${CLEANED_ANALYSIS_RESULTS}

          ## Test Generation:
          After approving, you can:
          - Reply \`/generate-tests\` to generate test cases

          *Generated by Mintify, View further Pull request info and AI suggestions in the [dashboard](https://bunjy.vercel.app/home)*
          EOF
          )

          # Post the comment
          curl -X POST \
            -H "Authorization: Bearer ${TOKEN}" \
            -H "Accept: application/vnd.github.v3+json" \
            -d "{\"body\": $(echo "$COMMENT_BODY" | jq -sR)}" \
            "https://api.github.com/repos/${REPO}/issues/${PR_NUMBER}/comments"
        env:
          TOKEN: ${{ env.TOKEN }}
          ANALYSIS_RESULTS: ${{ env.ANALYSIS_RESULTS }}
          REPO: ${{ github.repository }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          RUN_ID: ${{ github.run_id }}

      - name: Generate Tests
        if: env.GENERATE_TESTS == 'true'
        shell: bash
        run: |
          echo "Automatically generating tests..."
          test_results=""
          
          # Read the analyzed files
          if [ -f ".analysis-data/analyzed_files" ]; then
            while IFS= read -r file; do
              if [[ "$file" =~ \.(ts|js|tsx|jsx)$ ]]; then
                echo "Generating tests for $file"
                
                if [ -f "$file" ]; then
                  file_content=$(cat "$file")
                  markdown_content="### File: \`$file\`\n\n\`\`\`typescript\n${file_content}\n\`\`\`"
                  escaped_markdown=$(echo "$markdown_content" | jq -sR .)
                  
                  # Send request to the test generation service
                  echo "Sending request to ${BASE_APP_URL}/gemini/generate-tests..."
                  response=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -X POST "${BASE_APP_URL}/gemini/generate-tests" \
                    -H "Authorization: Bearer ${API_KEY}" \
                    -H "Content-Type: application/json" \
                    -d "{\"code\": ${escaped_markdown}}")
                  
                  http_status=$(echo "$response" | grep "HTTP_STATUS" | cut -d':' -f2)
                  raw_response=$(echo "$response" | sed -E 's/HTTP_STATUS:[0-9]+//')
                  
                  # Parse and clean the response if status is 200
                  if [ "$http_status" -eq 200 ] && [ -n "$raw_response" ]; then
                    echo "Processing response for $file"
                    
                    # Clean the response
                    formatted_response=$(echo "$raw_response" | sed -E 's/.*"formattedResponse":"?//; s/"[[:space:]]*}$//; s/\\n/\n/g; s/\\\"/"/g')
                    test_results="${test_results}\n## Tests for \`$file\`\n${formatted_response}\n---"
                  else
                    echo "Error: Request failed for $file with status $http_status"
                  fi
                else
                  echo "File $file does not exist."
                fi
              fi
            done < ".analysis-data/analyzed_files"
          fi

          # Post the comment only if there are results
          if [ -n "$test_results" ]; then
            echo "Tests generated successfully. Posting results to GitHub..."
            comment_body=$(cat << 'EOF'
            # ðŸ§ª Automatically Generated Tests

            ${test_results}

            *Review the generated tests and integrate them into your suite.*
            EOF
            )
            
            curl -X POST \
              -H "Authorization: Bearer ${TOKEN}" \
              -H "Accept: application/vnd.github.v3+json" \
              -d "{\"body\": $(echo "$comment_body" | jq -sR)}" \
              "https://api.github.com/repos/${REPO}/issues/${PR_NUMBER}/comments"
          else
            echo "No tests were generated. Skipping comment posting."
          fi
        env:
          TOKEN: ${{ env.TOKEN }}
          BASE_APP_URL: ${{ env.BASE_APP_URL }}
          API_KEY: ${{ env.API_KEY }}
          REPO: ${{ github.repository }}
          PR_NUMBER: ${{ github.event.pull_request.number }}

      # - name: Process Feedback
      #   if: github.event_name == 'issue_comment' && github.event.comment.body == '/generate-tests'
      #   shell: bash
      #   run: |                
      #     echo "Generating tests..."
      #     test_results=""
          
      #     # Read the analyzed files
      #     if [ -f ".analysis-data/analyzed_files" ]; then
      #         while IFS= read -r file; do
      #             # Focus on TypeScript/JavaScript files
      #             if [[ "$file" =~ \.(ts|js|tsx|jsx)$ ]]; then
      #                 echo "Generating tests for $file"
                      
      #                 if [ -f "$file" ]; then
      #                     file_content=$(cat "$file")
                          
      #                     # Format content as markdown
      #                     markdown_content="### File: \`$file\`\n\n\`\`\`typescript\n${file_content}\n\`\`\`"
      #                     escaped_markdown=$(echo "$markdown_content" | jq -sR .)
                          
      #                     # Send request to test generation service
      #                     test_response=$(curl -s -X POST "${BASE_APP_URL}/gemini/generate-tests" \
      #                         -H "Authorization: Bearer ${API_KEY}" \
      #                         -H "Content-Type: application/json" \
      #                         -d "{\"code\": ${escaped_markdown}}")
                          
      #                     if [ -n "$test_response" ]; then
      #                         test_results="${test_results}
      #     ## Tests for \`$file\`

      #     ${test_response}

      #     ---
      #     "
      #                     fi
      #                 fi
      #             fi
      #         done < ".analysis-data/analyzed_files"
      #     fi
          
      #     # Post test results or a message if no tests generated
      #     if [ -n "$test_results" ]; then
      #         comment_body="### ðŸ§ª Generated Tests

      #     ${test_results}

      #     *Review the generated tests and add them to your test suite if they look good.*"
      #     else
      #         comment_body="### âš ï¸ No Tests Generated
      #     No eligible files found for test generation or test generation failed."
      #     fi
          
      #     # Post comment with test results
      #     curl -X POST \
      #       -H "Authorization: Bearer ${TOKEN}" \
      #       -H "Accept: application/vnd.github.v3+json" \
      #       -d "{\"body\": $(echo "$comment_body" | jq -sR)}" \
      #       "https://api.github.com/repos/${REPO}/issues/${PR_NUMBER}/comments"
      #   env:
      #     TOKEN: ${{ env.TOKEN }}
      #     BASE_APP_URL: ${{ env.BASE_APP_URL }}
      #     API_KEY: ${{ env.API_KEY }}
      #     REPO: ${{ github.repository }}
      #     PR_NUMBER: ${{ github.event.issue.number }}

branding:
  icon: 'activity'
  color: 'blue'